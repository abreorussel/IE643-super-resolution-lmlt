{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1186423,
          "sourceType": "datasetVersion",
          "datasetId": 648388
        },
        {
          "sourceId": 3901202,
          "sourceType": "datasetVersion",
          "datasetId": 2317381
        },
        {
          "sourceId": 5376888,
          "sourceType": "datasetVersion",
          "datasetId": 3119036
        },
        {
          "sourceId": 6257030,
          "sourceType": "datasetVersion",
          "datasetId": 3596048
        },
        {
          "sourceId": 9559485,
          "sourceType": "datasetVersion",
          "datasetId": 5825268
        },
        {
          "sourceId": 9622144,
          "sourceType": "datasetVersion",
          "datasetId": 5872942
        },
        {
          "sourceId": 9737909,
          "sourceType": "datasetVersion",
          "datasetId": 5960184
        }
      ],
      "dockerImageVersionId": 30776,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-10-05T05:44:33.156397Z",
          "iopub.execute_input": "2024-10-05T05:44:33.156731Z",
          "iopub.status.idle": "2024-10-05T05:44:34.990524Z",
          "shell.execute_reply.started": "2024-10-05T05:44:33.156689Z",
          "shell.execute_reply": "2024-10-05T05:44:34.989218Z"
        },
        "trusted": true,
        "id": "UuYbGz6nvfTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abreorussel/IE643-super-resolution-lmlt.git"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:26:57.652631Z",
          "iopub.execute_input": "2024-11-05T12:26:57.653018Z",
          "iopub.status.idle": "2024-11-05T12:27:05.301674Z",
          "shell.execute_reply.started": "2024-11-05T12:26:57.652983Z",
          "shell.execute_reply": "2024-11-05T12:27:05.300392Z"
        },
        "trusted": true,
        "id": "6Cr3skdYvfTH",
        "outputId": "263bccb1-7ff9-44e1-b910-8537a9444f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'IE643-super-resolution-lmlt'...\nremote: Enumerating objects: 1743, done.\u001b[K\nremote: Counting objects: 100% (57/57), done.\u001b[K\nremote: Compressing objects: 100% (36/36), done.\u001b[K\nremote: Total 1743 (delta 19), reused 45 (delta 13), pack-reused 1686 (from 1)\u001b[K\nReceiving objects: 100% (1743/1743), 201.46 MiB | 41.32 MiB/s, done.\nResolving deltas: 100% (698/698), done.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IE643-super-resolution-lmlt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:27:05.303912Z",
          "iopub.execute_input": "2024-11-05T12:27:05.304265Z",
          "iopub.status.idle": "2024-11-05T12:27:05.310815Z",
          "shell.execute_reply.started": "2024-11-05T12:27:05.304227Z",
          "shell.execute_reply": "2024-11-05T12:27:05.309835Z"
        },
        "trusted": true,
        "id": "2hnMCCO1vfTI",
        "outputId": "3f0b4a8e-d2b2-409e-88fd-020497477487"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/working/IE643-super-resolution-lmlt\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the necessary packages and tools"
      ],
      "metadata": {
        "id": "k4txYOl3vfTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LMLT_forked\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:27:05.312131Z",
          "iopub.execute_input": "2024-11-05T12:27:05.312532Z",
          "iopub.status.idle": "2024-11-05T12:29:03.542125Z",
          "shell.execute_reply.started": "2024-11-05T12:27:05.312463Z",
          "shell.execute_reply": "2024-11-05T12:29:03.541004Z"
        },
        "trusted": true,
        "id": "XqWyegzdvfTK",
        "outputId": "30f6929d-0b65-4bae-e4ee-1bcbc6a6c723"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[Errno 2] No such file or directory: 'LMLT_forked'\n/kaggle/working/IE643-super-resolution-lmlt\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.1\n",
        "!python3 setup.py develop"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:29:03.545005Z",
          "iopub.execute_input": "2024-11-05T12:29:03.545443Z",
          "iopub.status.idle": "2024-11-05T12:29:55.756369Z",
          "shell.execute_reply.started": "2024-11-05T12:29:03.545396Z",
          "shell.execute_reply": "2024-11-05T12:29:55.755276Z"
        },
        "trusted": true,
        "id": "6buWnNdwvfTL",
        "outputId": "0af460c3-5725-47f1-8db6-ab2601f08d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting setuptools==65.5.1\n  Downloading setuptools-65.5.1-py3-none-any.whl.metadata (6.3 kB)\nDownloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 70.0.0\n    Uninstalling setuptools-70.0.0:\n      Successfully uninstalled setuptools-70.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nconda 24.7.1 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-65.5.1\nrunning develop\n/opt/conda/lib/python3.10/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n  warnings.warn(\nrunning egg_info\nwriting basicsr.egg-info/PKG-INFO\nwriting dependency_links to basicsr.egg-info/dependency_links.txt\nwriting requirements to basicsr.egg-info/requires.txt\nwriting top-level names to basicsr.egg-info/top_level.txt\nreading manifest template 'MANIFEST.in'\nadding license file 'LICENSE'\nwriting manifest file 'basicsr.egg-info/SOURCES.txt'\nrunning build_ext\nCreating /opt/conda/lib/python3.10/site-packages/basicsr.egg-link (link to .)\nAdding basicsr 1.3.4.8 to easy-install.pth file\n\nInstalled /kaggle/working/IE643-super-resolution-lmlt\nProcessing dependencies for basicsr==1.3.4.8\nSearching for fvcore==0.1.5.post20221221\nBest match: fvcore 0.1.5.post20221221\nAdding fvcore 0.1.5.post20221221 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for einops==0.8.0\nBest match: einops 0.8.0\nAdding einops 0.8.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for yapf==0.40.2\nBest match: yapf 0.40.2\nAdding yapf 0.40.2 to easy-install.pth file\nInstalling yapf script to /opt/conda/bin\nInstalling yapf-diff script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tqdm==4.66.4\nBest match: tqdm 4.66.4\nAdding tqdm 4.66.4 to easy-install.pth file\nInstalling tqdm script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for torchvision==0.19.0\nBest match: torchvision 0.19.0\nAdding torchvision 0.19.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for torch==1.13.1\nBest match: torch 1.13.1\nAdding torch 1.13.1 to easy-install.pth file\nInstalling convert-caffe2-to-onnx script to /opt/conda/bin\nInstalling convert-onnx-to-caffe2 script to /opt/conda/bin\nInstalling torchrun script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tb-nightly==2.19.0a20241105\nBest match: tb-nightly 2.19.0a20241105\nAdding tb-nightly 2.19.0a20241105 to easy-install.pth file\nInstalling tensorboard script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for scipy==1.14.1\nBest match: scipy 1.14.1\nAdding scipy 1.14.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for scikit-image==0.23.2\nBest match: scikit-image 0.23.2\nAdding scikit-image 0.23.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for requests==2.32.3\nBest match: requests 2.32.3\nAdding requests 2.32.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for PyYAML==6.0.2\nBest match: PyYAML 6.0.2\nAdding PyYAML 6.0.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for pillow==10.4.0\nBest match: pillow 10.4.0\nAdding pillow 10.4.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for opencv-python==4.10.0.84\nBest match: opencv-python 4.10.0.84\nAdding opencv-python 4.10.0.84 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for numpy==1.26.4\nBest match: numpy 1.26.4\nAdding numpy 1.26.4 to easy-install.pth file\nInstalling f2py script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for lmdb==1.5.1\nBest match: lmdb 1.5.1\nAdding lmdb 1.5.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for future==1.0.0\nBest match: future 1.0.0\nAdding future 1.0.0 to easy-install.pth file\nInstalling futurize script to /opt/conda/bin\nInstalling pasteurize script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for addict==2.4.0\nBest match: addict 2.4.0\nAdding addict 2.4.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for iopath==0.1.10\nBest match: iopath 0.1.10\nAdding iopath 0.1.10 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tabulate==0.9.0\nBest match: tabulate 0.9.0\nAdding tabulate 0.9.0 to easy-install.pth file\nInstalling tabulate script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for termcolor==2.4.0\nBest match: termcolor 2.4.0\nAdding termcolor 2.4.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for yacs==0.1.8\nBest match: yacs 0.1.8\nAdding yacs 0.1.8 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tomli==2.0.1\nBest match: tomli 2.0.1\nAdding tomli 2.0.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for platformdirs==4.2.2\nBest match: platformdirs 4.2.2\nAdding platformdirs 4.2.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for importlib-metadata==7.0.0\nBest match: importlib-metadata 7.0.0\nAdding importlib-metadata 7.0.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for nvidia-cuda-nvrtc-cu11==11.7.99\nBest match: nvidia-cuda-nvrtc-cu11 11.7.99\nAdding nvidia-cuda-nvrtc-cu11 11.7.99 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for nvidia-cublas-cu11==11.10.3.66\nBest match: nvidia-cublas-cu11 11.10.3.66\nAdding nvidia-cublas-cu11 11.10.3.66 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for nvidia-cudnn-cu11==8.5.0.96\nBest match: nvidia-cudnn-cu11 8.5.0.96\nAdding nvidia-cudnn-cu11 8.5.0.96 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for nvidia-cuda-runtime-cu11==11.7.99\nBest match: nvidia-cuda-runtime-cu11 11.7.99\nAdding nvidia-cuda-runtime-cu11 11.7.99 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for typing-extensions==4.12.2\nBest match: typing-extensions 4.12.2\nAdding typing-extensions 4.12.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for werkzeug==3.0.4\nBest match: werkzeug 3.0.4\nAdding werkzeug 3.0.4 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tensorboard-data-server==0.7.2\nBest match: tensorboard-data-server 0.7.2\nAdding tensorboard-data-server 0.7.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for six==1.16.0\nBest match: six 1.16.0\nAdding six 1.16.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for setuptools==65.5.1\nBest match: setuptools 65.5.1\nAdding setuptools 65.5.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for protobuf==4.25.3\nBest match: protobuf 4.25.3\nAdding protobuf 4.25.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for packaging==21.3\nBest match: packaging 21.3\nAdding packaging 21.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for Markdown==3.6\nBest match: Markdown 3.6\nAdding Markdown 3.6 to easy-install.pth file\nInstalling markdown_py script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for grpcio==1.64.1\nBest match: grpcio 1.64.1\nAdding grpcio 1.64.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for absl-py==1.4.0\nBest match: absl-py 1.4.0\nAdding absl-py 1.4.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for lazy-loader==0.4\nBest match: lazy-loader 0.4\nAdding lazy-loader 0.4 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for tifffile==2024.5.22\nBest match: tifffile 2024.5.22\nAdding tifffile 2024.5.22 to easy-install.pth file\nInstalling lsm2bin script to /opt/conda/bin\nInstalling tiff2fsspec script to /opt/conda/bin\nInstalling tiffcomment script to /opt/conda/bin\nInstalling tifffile script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for imageio==2.34.1\nBest match: imageio 2.34.1\nAdding imageio 2.34.1 to easy-install.pth file\nInstalling imageio_download_bin script to /opt/conda/bin\nInstalling imageio_remove_bin script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for networkx==3.3\nBest match: networkx 3.3\nAdding networkx 3.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for certifi==2024.8.30\nBest match: certifi 2024.8.30\nAdding certifi 2024.8.30 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for urllib3==2.2.1\nBest match: urllib3 2.2.1\nAdding urllib3 2.2.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for idna==3.7\nBest match: idna 3.7\nAdding idna 3.7 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for charset-normalizer==3.3.2\nBest match: charset-normalizer 3.3.2\nAdding charset-normalizer 3.3.2 to easy-install.pth file\nInstalling normalizer script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for portalocker==2.10.1\nBest match: portalocker 2.10.1\nAdding portalocker 2.10.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for zipp==3.19.2\nBest match: zipp 3.19.2\nAdding zipp 3.19.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for wheel==0.43.0\nBest match: wheel 0.43.0\nAdding wheel 0.43.0 to easy-install.pth file\nInstalling wheel script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for MarkupSafe==2.1.5\nBest match: MarkupSafe 2.1.5\nAdding MarkupSafe 2.1.5 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nSearching for pyparsing==3.1.4\nBest match: pyparsing 3.1.4\nAdding pyparsing 3.1.4 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.10/site-packages\nFinished processing dependencies for basicsr==1.3.4.8\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch==2.0.0 torchvision==0.15.0 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:29:55.758075Z",
          "iopub.execute_input": "2024-11-05T12:29:55.758968Z",
          "iopub.status.idle": "2024-11-05T12:31:54.947547Z",
          "shell.execute_reply.started": "2024-11-05T12:29:55.758921Z",
          "shell.execute_reply": "2024-11-05T12:31:54.946423Z"
        },
        "trusted": true,
        "id": "vSYSB9WLvfTL",
        "outputId": "e66bbec3-0c0e-4376-fc4c-3677149babaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found existing installation: torch 1.13.1\nUninstalling torch-1.13.1:\n  Successfully uninstalled torch-1.13.1\nFound existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\nLooking in indexes: https://download.pytorch.org/whl/cu118\nCollecting torch==2.0.0\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.0\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1.4)\nCollecting triton==2.0.0 (from torch==2.0.0)\n  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.0) (10.3.0)\nCollecting cmake (from triton==2.0.0->torch==2.0.0)\n  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.0)\n  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\nBuilding wheels for collected packages: lit\n  Building wheel for lit (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89987 sha256=bac763ffdc5c6dec6cad8635c17c5f01ce7e8e5422f2417ff8d7ea3145e97640\n  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\nSuccessfully built lit\nInstalling collected packages: lit, cmake, triton, torch, torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0+cu118 which is incompatible.\nbasicsr 1.3.4.8 requires torch==1.13.1, but you have torch 2.0.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.25.0 lit-15.0.7 torch-2.0.0+cu118 torchvision-0.15.0+cu118 triton-2.0.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing Patches"
      ],
      "metadata": {
        "id": "tQKI5wwrvqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performed patch extraction by running this script on local machine . Then uploaded this final processed dataset on kaggle\n",
        "\n",
        "# !python process_real_sr_dataset.py --directory_path \"C:\\\\Users\\\\abreo\\\\Downloads\\\\archive (2)\\\\RealSR (ICCV2019)\" --new_directory_name \"realsr\"  --scale \"4\"\n",
        "# !python3 scripts/data_preparation/extract_subimages_realsr.py"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-14T11:10:40.170475Z",
          "iopub.execute_input": "2024-10-14T11:10:40.170844Z",
          "iopub.status.idle": "2024-10-14T11:12:12.966478Z",
          "shell.execute_reply.started": "2024-10-14T11:10:40.170808Z",
          "shell.execute_reply": "2024-10-14T11:12:12.965554Z"
        },
        "trusted": true,
        "id": "s_YopeaPvfTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwdb()\n",
        "! git pull"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T07:14:13.538430Z",
          "iopub.execute_input": "2024-11-05T07:14:13.539365Z",
          "iopub.status.idle": "2024-11-05T07:14:14.919471Z",
          "shell.execute_reply.started": "2024-11-05T07:14:13.539318Z",
          "shell.execute_reply": "2024-11-05T07:14:14.918378Z"
        },
        "trusted": true,
        "id": "42sEX8jKvfTN",
        "outputId": "03ebb6df-baed-4859-fbeb-5434b5b9061c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Already up to date.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Datasets to working directory for Testing"
      ],
      "metadata": {
        "id": "G009mLH5vfTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copytree('/kaggle/input/realsr-subimages-dataset/RealSR (ICCV2019)', '/kaggle/working/RealSR (ICCV2019)')\n",
        "shutil.copytree('/kaggle/input/set5-superresolution/Set5', '/kaggle/working/Set5')\n",
        "shutil.copytree('/kaggle/input/urban100/Urban100', '/kaggle/working/urban100')\n",
        "shutil.copytree('/kaggle/input/set14dataset/Set14', '/kaggle/working/Set14')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:33:51.595747Z",
          "iopub.execute_input": "2024-11-05T12:33:51.596078Z",
          "iopub.status.idle": "2024-11-05T12:33:58.729198Z",
          "shell.execute_reply.started": "2024-11-05T12:33:51.596045Z",
          "shell.execute_reply": "2024-11-05T12:33:58.728272Z"
        },
        "trusted": true,
        "id": "T0OR5BZLvfTO",
        "outputId": "d0a8b1d3-50c4-40b2-a7fb-b21467bed9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/Set14'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning the model"
      ],
      "metadata": {
        "id": "LfFMRuEnvfTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 basicsr/train.py -opt options/finetune/LMLT/finetune_base_RealSR_X2.yml"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-05T12:33:58.730414Z",
          "iopub.execute_input": "2024-11-05T12:33:58.730723Z"
        },
        "trusted": true,
        "id": "cTSVGejLvfTP",
        "outputId": "0ad1ef97-9d6c-4fb0-cd77-4623478f582d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Disable distributed.\nopt path : OrderedDict([('pretrain_network_g', '/kaggle/working/IE643-super-resolution-lmlt/experiments/pretrained_model/LMLT_base_x2_new.pth'), ('strict_load_g', True), ('resume_state', None), ('experiments_root', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2'), ('models', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/models'), ('training_states', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/training_states'), ('log', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2'), ('visualization', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/visualization'), ('bic_visualization', '/kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/bic_visualization')])\nPath : /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/models\nPath : /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/training_states\nPath : /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2\nPath : /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/visualization\nPath : /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/bic_visualization\n2024-11-05 12:34:04,578 INFO: \n                ____                _       _____  ____\n               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n     ______                   __   __                 __      __\n    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n    \nVersion Information: \n\tBasicSR: 1.3.4.8\n\tPyTorch: 2.0.0+cu118\n\tTorchVision: 0.15.0+cu118\n2024-11-05 12:34:04,578 INFO: \n  name: LMLT_Base_DF2K_X2\n  model_type: SRModel\n  scale: 2\n  num_gpu: 1\n  manual_seed: 10\n  datasets:[\n    train:[\n      name: RealSR\n      type: PairedImageDataset\n      dataroot_gt: /kaggle/working/RealSR (ICCV2019)/realsr/Train/HR_sub\n      dataroot_lq: /kaggle/working/RealSR (ICCV2019)/realsr/Train/X2_sub\n      filename_tmpl: {}\n      io_backend:[\n        type: disk\n      ]\n      gt_size: 128\n      use_hflip: True\n      use_rot: True\n      use_shuffle: True\n      num_worker_per_gpu: 8\n      batch_size_per_gpu: 64\n      dataset_enlarge_ratio: 10\n      prefetch_mode: None\n      phase: train\n      scale: 2\n    ]\n    val:[\n      name: RealSR\n      type: PairedImageDataset\n      dataroot_gt: /kaggle/working/RealSR (ICCV2019)/realsr/Val/HR\n      dataroot_lq: /kaggle/working/RealSR (ICCV2019)/realsr/Val/X2\n      filename_tmpl: {}x2\n      io_backend:[\n        type: disk\n      ]\n      phase: val\n      scale: 2\n    ]\n    val_set5:[\n      name: Set5\n      type: PairedImageDataset\n      dataroot_gt: /kaggle/working/Set5/original\n      dataroot_lq: /kaggle/working/Set5/LRbicx2\n      filename_tmpl: {}\n      io_backend:[\n        type: disk\n      ]\n      phase: val\n      scale: 2\n    ]\n    val_urban100:[\n      name: Urban100\n      type: PairedImageDataset\n      dataroot_gt: /kaggle/working/urban100/HR\n      dataroot_lq: /kaggle/working/urban100/LR_bicubic/X2\n      filename_tmpl: {}x2\n      io_backend:[\n        type: disk\n      ]\n      phase: val\n      scale: 2\n    ]\n  ]\n  network_g:[\n    type: LMLT\n    dim: 60\n    n_blocks: 8\n    ffn_scale: 2.0\n    upscaling_factor: 2\n  ]\n  network_teacher:[\n    type: LMLT\n    dim: 60\n    n_blocks: 8\n    ffn_scale: 2.0\n    upscaling_factor: 2\n  ]\n  path:[\n    pretrain_network_g: /kaggle/working/IE643-super-resolution-lmlt/experiments/pretrained_model/LMLT_base_x2_new.pth\n    strict_load_g: True\n    resume_state: None\n    experiments_root: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2\n    models: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/models\n    training_states: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/training_states\n    log: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2\n    visualization: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/visualization\n    bic_visualization: /kaggle/working/IE643-super-resolution-lmlt/experiments/LMLT_Base_DF2K_X2/bic_visualization\n  ]\n  train:[\n    finetune: True\n    epochs: None\n    ema_decay: 0.999\n    optim_g:[\n      type: Adam\n      lr: 5e-06\n      weight_decay: 0\n      betas: [0.9, 0.99]\n    ]\n    scheduler:[\n      type: CosineAnnealingRestartLR\n      periods: [500000]\n      restart_weights: [1]\n      eta_min: 5e-07\n    ]\n    total_iter: 15000\n    warmup_iter: -1\n    pixel_opt:[\n      type: L1Loss\n      loss_weight: 1.0\n      reduction: mean\n    ]\n    distillation:[\n      type: L1Loss\n      initial_distill_weight: 0.5\n      min_distill_weight: 0.2\n      weight_decay_epochs: 2\n      loss_weight: 0.5\n      reduction: mean\n    ]\n    fft_opt:[\n      type: FFTLoss\n      loss_weight: 0.05\n      reduction: mean\n    ]\n  ]\n  val:[\n    val_freq: 825.0\n    save_img: False\n    pbar: False\n    bic: False\n    metrics:[\n      psnr:[\n        type: calculate_psnr\n        crop_border: 2\n        test_y_channel: True\n        better: higher\n      ]\n      ssim:[\n        type: calculate_ssim\n        crop_border: 2\n        test_y_channel: True\n        better: higher\n      ]\n    ]\n  ]\n  logger:[\n    print_freq: 100\n    save_checkpoint_freq: 5000.0\n    use_tb_logger: True\n    wandb:[\n      project: None\n      resume_id: None\n    ]\n  ]\n  dist_params:[\n    backend: nccl\n    port: 29500\n  ]\n  dist: False\n  rank: 0\n  world_size: 1\n  auto_resume: False\n  is_train: True\n  root_path: /kaggle/working/IE643-super-resolution-lmlt\n\n2024-11-05 12:34:25,828 INFO: Dataset [PairedImageDataset] - RealSR is built.\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n2024-11-05 12:34:25,829 INFO: Training statistics:\n\tNumber of train images: 5277\n\tDataset enlarge ratio: 10\n\tBatch size per gpu: 64\n\tWorld size (gpu number): 1\n\tRequire iter number per epoch: 825\n\tTotal epochs: 19; iters: 15000.\n2024-11-05 12:34:25,831 INFO: Dataset [PairedImageDataset] - RealSR is built.\n2024-11-05 12:34:25,831 INFO: Number of val images/folders in RealSR: 30\n2024-11-05 12:34:25,832 INFO: Dataset [PairedImageDataset] - Set5 is built.\n2024-11-05 12:34:25,832 INFO: Number of val images/folders in Set5: 5\n2024-11-05 12:34:25,837 INFO: Dataset [PairedImageDataset] - Urban100 is built.\n2024-11-05 12:34:25,837 INFO: Number of val images/folders in Urban100: 100\n2024-11-05 12:34:25,865 INFO: Network [LMLT] is created.\n2024-11-05 12:34:26,141 INFO: Network: LMLT, with parameters: 652,332\n2024-11-05 12:34:26,141 INFO: LMLT(\n  (to_feat): Conv2d(3, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pos_drop): Dropout(p=0.1, inplace=False)\n  (feats): Sequential(\n    (0): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (1): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (2): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (3): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (4): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (5): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (6): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (7): AttBlock(\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (lhsb): LHSB(\n        (mfr): ModuleList(\n          (0-3): 4 x downsample_vit(\n            (qkv): Linear(in_features=15, out_features=45, bias=True)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=15, out_features=15, bias=True)\n            (proj_drop): Dropout(p=0.1, inplace=False)\n            (get_v): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)\n          )\n        )\n        (aggr): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n        (act): GELU(approximate='none')\n      )\n      (ccm): CCM(\n        (ccm): Sequential(\n          (0): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): GELU(approximate='none')\n          (2): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n  (to_img): Sequential(\n    (0): Conv2d(60, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): PixelShuffle(upscale_factor=2)\n  )\n)\n2024-11-05 12:34:26,168 INFO: Network [LMLT] is created.\nCurrent Location : b'/kaggle/working/IE643-super-resolution-lmlt'\nModel Keys(LMLT) : dict_keys(['params', 'params_ema'])\n2024-11-05 12:34:26,358 INFO: Loading LMLT model from /kaggle/working/IE643-super-resolution-lmlt/experiments/pretrained_model/LMLT_base_x2_new.pth, with param key: [params].\nTeacher network loaded for knowledge distillation.\nLOADING PRETRAINED MODEL\nCurrent Location : b'/kaggle/working/IE643-super-resolution-lmlt'\nModel Keys(LMLT) : dict_keys(['params', 'params_ema'])\n2024-11-05 12:34:26,412 INFO: Loading LMLT model from /kaggle/working/IE643-super-resolution-lmlt/experiments/pretrained_model/LMLT_base_x2_new.pth, with param key: [params].\nFreezing the model layers  ..............\nFreezing  the Attention Blocks ..........\n2024-11-05 12:34:26,443 INFO: Use Exponential Moving Average with decay: 0.999\n2024-11-05 12:34:26,466 INFO: Network [LMLT] is created.\nCurrent Location : b'/kaggle/working/IE643-super-resolution-lmlt'\nModel Keys(LMLT) : dict_keys(['params', 'params_ema'])\n2024-11-05 12:34:26,501 INFO: Loading LMLT model from /kaggle/working/IE643-super-resolution-lmlt/experiments/pretrained_model/LMLT_base_x2_new.pth, with param key: [params_ema].\n2024-11-05 12:34:26,530 INFO: Loss [L1Loss] is created.\n2024-11-05 12:34:26,530 INFO: Loss [FFTLoss] is created.\n2024-11-05 12:34:26,530 WARNING: Params to_feat.weight will not be optimized.\n2024-11-05 12:34:26,530 WARNING: Params to_feat.bias will not be optimized.\n2024-11-05 12:34:26,530 WARNING: Params feats.0.norm1.weight will not be optimized.\n2024-11-05 12:34:26,530 WARNING: Params feats.0.norm1.bias will not be optimized.\n2024-11-05 12:34:26,530 WARNING: Params feats.0.norm2.weight will not be optimized.\n2024-11-05 12:34:26,530 WARNING: Params feats.0.norm2.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.qkv.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.qkv.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.proj.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.proj.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.get_v.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.0.get_v.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.qkv.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.qkv.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.proj.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.proj.bias will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.get_v.weight will not be optimized.\n2024-11-05 12:34:26,531 WARNING: Params feats.0.lhsb.mfr.1.get_v.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.qkv.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.qkv.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.proj.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.proj.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.get_v.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.2.get_v.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.qkv.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.qkv.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.proj.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.proj.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.get_v.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.mfr.3.get_v.bias will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.aggr.weight will not be optimized.\n2024-11-05 12:34:26,532 WARNING: Params feats.0.lhsb.aggr.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.0.ccm.ccm.0.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.0.ccm.ccm.0.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.0.ccm.ccm.2.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.0.ccm.ccm.2.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.norm1.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.norm1.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.norm2.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.norm2.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.qkv.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.qkv.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.proj.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.proj.bias will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.get_v.weight will not be optimized.\n2024-11-05 12:34:26,533 WARNING: Params feats.1.lhsb.mfr.0.get_v.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.qkv.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.qkv.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.proj.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.proj.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.get_v.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.1.get_v.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.qkv.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.qkv.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.proj.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.proj.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.get_v.weight will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.2.get_v.bias will not be optimized.\n2024-11-05 12:34:26,534 WARNING: Params feats.1.lhsb.mfr.3.qkv.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.mfr.3.qkv.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.mfr.3.proj.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.mfr.3.proj.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.mfr.3.get_v.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.mfr.3.get_v.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.aggr.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.lhsb.aggr.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.ccm.ccm.0.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.ccm.ccm.0.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.ccm.ccm.2.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.1.ccm.ccm.2.bias will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.2.norm1.weight will not be optimized.\n2024-11-05 12:34:26,535 WARNING: Params feats.2.norm1.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.norm2.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.norm2.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.qkv.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.qkv.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.proj.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.proj.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.get_v.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.0.get_v.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.1.qkv.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.1.qkv.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.1.proj.weight will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.1.proj.bias will not be optimized.\n2024-11-05 12:34:26,536 WARNING: Params feats.2.lhsb.mfr.1.get_v.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.1.get_v.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.qkv.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.qkv.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.proj.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.proj.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.get_v.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.2.get_v.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.qkv.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.qkv.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.proj.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.proj.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.get_v.weight will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.mfr.3.get_v.bias will not be optimized.\n2024-11-05 12:34:26,537 WARNING: Params feats.2.lhsb.aggr.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.2.lhsb.aggr.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.2.ccm.ccm.0.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.2.ccm.ccm.0.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.2.ccm.ccm.2.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.2.ccm.ccm.2.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.norm1.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.norm1.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.norm2.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.norm2.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.lhsb.mfr.0.qkv.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.lhsb.mfr.0.qkv.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.lhsb.mfr.0.proj.weight will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.lhsb.mfr.0.proj.bias will not be optimized.\n2024-11-05 12:34:26,538 WARNING: Params feats.3.lhsb.mfr.0.get_v.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.0.get_v.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.qkv.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.qkv.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.proj.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.proj.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.get_v.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.1.get_v.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.qkv.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.qkv.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.proj.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.proj.bias will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.get_v.weight will not be optimized.\n2024-11-05 12:34:26,539 WARNING: Params feats.3.lhsb.mfr.2.get_v.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.qkv.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.qkv.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.proj.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.proj.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.get_v.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.mfr.3.get_v.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.aggr.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.lhsb.aggr.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.ccm.ccm.0.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.ccm.ccm.0.bias will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.ccm.ccm.2.weight will not be optimized.\n2024-11-05 12:34:26,540 WARNING: Params feats.3.ccm.ccm.2.bias will not be optimized.\n2024-11-05 12:34:26,542 INFO: Model [SRModel] is created.\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n2024-11-05 12:34:26,696 INFO: Start training from epoch: 0, iter: 0\n2024-11-05 12:36:05,545 INFO: [LMLT_..][epoch:  0, iter:     100, lr:(5.000e-06,)] [eta: 3:41:43, time (data): 0.988 (0.051)] l_distill: 6.1090e-03 l_pix: 2.5118e-02 l_freq: 1.2992e-01 \n2024-11-05 12:37:39,313 INFO: [LMLT_..][epoch:  0, iter:     200, lr:(5.000e-06,)] [eta: 3:45:44, time (data): 0.963 (0.028)] l_distill: 2.1089e-03 l_pix: 2.0301e-02 l_freq: 7.0915e-02 \n2024-11-05 12:39:13,126 INFO: [LMLT_..][epoch:  0, iter:     300, lr:(5.000e-06,)] [eta: 3:46:04, time (data): 0.938 (0.005)] l_distill: 1.5267e-02 l_pix: 3.3721e-02 l_freq: 1.8748e-01 \n2024-11-05 12:40:47,018 INFO: [LMLT_..][epoch:  0, iter:     400, lr:(5.000e-06,)] [eta: 3:45:30, time (data): 0.939 (0.005)] l_distill: 3.0297e-03 l_pix: 2.1575e-02 l_freq: 9.2312e-02 \n2024-11-05 12:42:20,951 INFO: [LMLT_..][epoch:  0, iter:     500, lr:(5.000e-06,)] [eta: 3:44:34, time (data): 0.939 (0.005)] l_distill: 6.4281e-03 l_pix: 2.5853e-02 l_freq: 1.3499e-01 \n2024-11-05 12:43:54,846 INFO: [LMLT_..][epoch:  0, iter:     600, lr:(5.000e-06,)] [eta: 3:43:24, time (data): 0.939 (0.005)] l_distill: 3.1929e-03 l_pix: 2.1890e-02 l_freq: 8.2629e-02 \n2024-11-05 12:45:28,632 INFO: [LMLT_..][epoch:  0, iter:     700, lr:(5.000e-06,)] [eta: 3:42:05, time (data): 0.938 (0.005)] l_distill: 4.0850e-03 l_pix: 2.2744e-02 l_freq: 9.9120e-02 \n2024-11-05 12:47:02,528 INFO: [LMLT_..][epoch:  0, iter:     800, lr:(5.000e-06,)] [eta: 3:40:44, time (data): 0.938 (0.005)] l_distill: 2.9204e-03 l_pix: 2.2627e-02 l_freq: 8.0126e-02 \n2024-11-05 12:47:25,081 INFO: Saving model at the end of epoch 0\n2024-11-05 12:47:28,350 WARNING: Multiple validation datasets are *only* supported by SRModel.\n2024-11-05 12:48:50,312 INFO: Validation RealSR\n\t # psnr: 32.3132\tBest: 32.3132 @ 825 iter\n\t # ssim: 0.8987\tBest: 0.8987 @ 825 iter\n\n2024-11-05 12:48:52,085 INFO: Validation Set5\n\t # psnr: 38.0451\tBest: 38.0451 @ 825 iter\n\t # ssim: 0.9612\tBest: 0.9612 @ 825 iter\n\n2024-11-05 12:49:51,339 INFO: Validation Urban100\n\t # psnr: 32.4292\tBest: 32.4292 @ 825 iter\n\t # ssim: 0.9306\tBest: 0.9306 @ 825 iter\n\n2024-11-05 12:51:02,181 INFO: [LMLT_..][epoch:  1, iter:     900, lr:(5.000e-06,)] [eta: 4:17:21, time (data): 0.963 (0.029)] l_distill: 4.0279e-03 l_pix: 2.1345e-02 l_freq: 9.6488e-02 \n2024-11-05 12:52:36,020 INFO: [LMLT_..][epoch:  1, iter:   1,000, lr:(5.000e-06,)] [eta: 4:11:53, time (data): 0.951 (0.017)] l_distill: 1.9491e-03 l_pix: 2.0657e-02 l_freq: 5.9449e-02 \n2024-11-05 12:54:09,757 INFO: [LMLT_..][epoch:  1, iter:   1,100, lr:(5.000e-06,)] [eta: 4:07:05, time (data): 0.937 (0.005)] l_distill: 2.7071e-03 l_pix: 2.3007e-02 l_freq: 7.9656e-02 \n2024-11-05 12:55:43,602 INFO: [LMLT_..][epoch:  1, iter:   1,200, lr:(5.000e-06,)] [eta: 4:02:51, time (data): 0.938 (0.005)] l_distill: 2.3961e-03 l_pix: 2.0055e-02 l_freq: 6.3203e-02 \n2024-11-05 12:57:17,460 INFO: [LMLT_..][epoch:  1, iter:   1,300, lr:(5.000e-06,)] [eta: 3:59:02, time (data): 0.939 (0.005)] l_distill: 2.1785e-03 l_pix: 2.0000e-02 l_freq: 5.9306e-02 \n2024-11-05 12:58:51,316 INFO: [LMLT_..][epoch:  1, iter:   1,400, lr:(5.000e-06,)] [eta: 3:55:32, time (data): 0.939 (0.005)] l_distill: 2.5578e-03 l_pix: 2.0157e-02 l_freq: 6.9943e-02 \n2024-11-05 13:00:25,112 INFO: [LMLT_..][epoch:  1, iter:   1,500, lr:(5.000e-06,)] [eta: 3:52:17, time (data): 0.938 (0.005)] l_distill: 3.0052e-03 l_pix: 2.0708e-02 l_freq: 6.7134e-02 \n2024-11-05 13:01:58,932 INFO: [LMLT_..][epoch:  1, iter:   1,600, lr:(5.000e-06,)] [eta: 3:49:15, time (data): 0.938 (0.005)] l_distill: 2.8082e-03 l_pix: 2.0269e-02 l_freq: 6.8667e-02 \n2024-11-05 13:02:44,049 INFO: Saving model at the end of epoch 1\n2024-11-05 13:02:48,856 WARNING: Multiple validation datasets are *only* supported by SRModel.\n2024-11-05 13:03:43,699 INFO: Validation RealSR\n\t # psnr: 32.3431\tBest: 32.3431 @ 1650 iter\n\t # ssim: 0.8993\tBest: 0.8993 @ 1650 iter\n\n2024-11-05 13:03:44,902 INFO: Validation Set5\n\t # psnr: 37.8992\tBest: 38.0451 @ 825 iter\n\t # ssim: 0.9605\tBest: 0.9612 @ 825 iter\n\n2024-11-05 13:04:38,939 INFO: Validation Urban100\n\t # psnr: 32.0653\tBest: 32.4292 @ 825 iter\n\t # ssim: 0.9274\tBest: 0.9306 @ 825 iter\n\n2024-11-05 13:05:26,317 INFO: [LMLT_..][epoch:  2, iter:   1,700, lr:(5.000e-06,)] [eta: 4:01:11, time (data): 0.972 (0.036)] l_distill: 2.3920e-03 l_pix: 1.9453e-02 l_freq: 5.5400e-02 \n2024-11-05 13:07:00,059 INFO: [LMLT_..][epoch:  2, iter:   1,800, lr:(5.000e-06,)] [eta: 3:57:32, time (data): 0.954 (0.020)] l_distill: 2.2535e-03 l_pix: 1.8243e-02 l_freq: 5.2900e-02 \n2024-11-05 13:08:33,818 INFO: [LMLT_..][epoch:  2, iter:   1,900, lr:(5.000e-06,)] [eta: 3:54:06, time (data): 0.938 (0.005)] l_distill: 2.6694e-03 l_pix: 1.8916e-02 l_freq: 5.9265e-02 \n2024-11-05 13:10:07,644 INFO: [LMLT_..][epoch:  2, iter:   2,000, lr:(5.000e-06,)] [eta: 3:50:51, time (data): 0.938 (0.005)] l_distill: 3.1015e-03 l_pix: 2.2512e-02 l_freq: 7.9852e-02 \n2024-11-05 13:11:41,504 INFO: [LMLT_..][epoch:  2, iter:   2,100, lr:(5.000e-06,)] [eta: 3:47:47, time (data): 0.938 (0.005)] l_distill: 2.8131e-03 l_pix: 1.8290e-02 l_freq: 6.5200e-02 \n2024-11-05 13:13:15,319 INFO: [LMLT_..][epoch:  2, iter:   2,200, lr:(5.000e-06,)] [eta: 3:44:50, time (data): 0.938 (0.005)] l_distill: 2.8826e-03 l_pix: 2.0601e-02 l_freq: 6.7198e-02 \n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/IE643-super-resolution-lmlt/basicsr/train.py\", line 218, in <module>\n    train_pipeline(root_path)\n  File \"/kaggle/working/IE643-super-resolution-lmlt/basicsr/train.py\", line 170, in train_pipeline\n    model.optimize_parameters(current_iter , epoch)\n  File \"/kaggle/working/IE643-super-resolution-lmlt/basicsr/models/sr_model.py\", line 209, in optimize_parameters\n    self.model_ema(decay=self.ema_decay)\n  File \"/kaggle/working/IE643-super-resolution-lmlt/basicsr/models/base_model.py\", line 78, in model_ema\n    net_g_params = dict(net_g.named_parameters())\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2115, in named_parameters\n    yield from gen\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2049, in _named_members\n    for module_prefix, module in modules:\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2266, in named_modules\n    for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2266, in named_modules\n    for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2266, in named_modules\n    for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n  [Previous line repeated 3 more times]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2260, in named_modules\n    memo.add(self)\nKeyboardInterrupt\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}